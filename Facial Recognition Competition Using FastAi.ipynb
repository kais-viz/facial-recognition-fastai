{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Using the Facial Recognition Challenge dataset with fastai\n\nThis is my take on lesson's [one](https://course.fast.ai/videos/?lesson=1) and [two](https://course.fast.ai/videos/?lesson=2) of the fastai course. I decided to use this library and see how well it will work out of the box on the [2013 facial recognition challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge)."},{"metadata":{},"cell_type":"markdown","source":"## Adding 2013 Facial Recognition dataset to the kernel\nBefore we start, we must upload the FER dataset to our kernel, to do so I followed the instructions of [this post on kaggle](https://www.kaggle.com/product-feedback/45472).\n\nClick on **File** and then **Add or upload data** from within a kernel you are editing. Youâ€™ll see that **Competition Data** is now listed alongside Datasets and Kernel Output Files in the popup. You can search for specific competitions using the search box.\n![competition-data](https://i.imgur.com/ndFipL4.png)"},{"metadata":{},"cell_type":"markdown","source":"Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":false},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We import all the necessary packages. We are going to work with the [fastai V1 library](http://www.fast.ai/2018/10/02/fastai-ai/) which sits on top of [Pytorch 1.0](https://hackernoon.com/pytorch-1-0-468332ba5163). The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.\n\nWe will also import [fastai.widgets](https://docs.fast.ai/widgets.image_cleaner.html#Image-Cleaner-Widget) which offer several widgets to support the workflow of a deep learning practitioner. The purpose of the widgets is to help you organize, clean, and prepare your data for your model. Widgets are separated by data type."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":false},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.widgets import *\n\nimport os\nimport sys\nimport cv2\nimport shutil  \nimport tarfile\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I ran into a little issue with the csv file, and only the one I extracted from the competition source works as intended. Because of this, I had to move the fer2013.tar.gz file to the working directory because the input directory is read-only."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Set the path to the dataset directory (needs to be movings to kaggle/working to be extracted because the input folder is read-only)\npath = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge'\n\nos.chdir(path)\n\nprint(f\"Before moving file, file path is:\\n{os.getcwd()}\\n\\nThe directory contains:\\n{os.listdir(path)} \\n\")  \n\n# Destination path  \ndestination = '/kaggle/working'\n\nif not os.path.isdir('/kaggle/working/challenges-in-representation-learning-facial-expression-recognition-challenge'):\n    try:\n        # Lets move fer2013.tar.gz to working\n        dest = shutil.move(path, destination)\n    except OSError:\n        print(sys.exc_info())\n\n    \n# Remove files\n# shutil.rmtree(\"/kaggle/working/challenges-in-representation-learning-facial-expression-recognition-challenge\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Let's rename the folder name since it's too long\nif not os.path.isdir('/kaggle/working/fer-challenge'):\n    os.rename(\"/kaggle/working/challenges-in-representation-learning-facial-expression-recognition-challenge\", \"/kaggle/working/fer-challenge\")\n\n# Set path to where we moved the dataset in output/working\nos.chdir(\"/kaggle/working/fer-challenge\")\n\n# Extract fer2013tar.gz \ntf = tarfile.open(\"fer2013.tar.gz\")\ntf.extractall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The competition dataset gives us a csv file with sets of pixels rather than the images themselves, the code below taken from the [competition's decision](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/discussion/29428) lets us convert those pixels to black and white images.\n\nThanks to [MadScientist](https://www.kaggle.com/madmlscientist) for this code snippet.\n"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"output_path =  \"/kaggle/working/fer-challenge/images\"\n\nif os.path.exists(output_path):\n    os.system('rm -rf {}'.format(output_path))\n\nos.system('mkdir {}'.format(output_path))\n\nlabel_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndata = np.genfromtxt('fer2013/fer2013.csv',delimiter=',',dtype=None, encoding=None)\nlabels = data[1:,0].astype(np.int32)\nimage_buffer = data[1:,1]\nimages = np.array([np.fromstring(image, np.uint8, sep=' ') for image in image_buffer])\nusage = data[1:,2]\ndataset = zip(labels, images, usage)\nusage_path = \"\"\nfor i, d in enumerate(dataset):\n    if(d[-1] == \"Training\" or d[-1] == \"PrivateTest\"):\n        usage_path = os.path.join(output_path, \"Training\")\n    else:\n        usage_path = os.path.join(output_path, d[-1])\n\n    label_path = os.path.join(usage_path, label_names[d[0]])\n    img = d[1].reshape((48,48))\n    img_name = '%08d.jpg' % i\n    img_path = os.path.join(label_path, img_name)\n    if not os.path.exists(usage_path):\n        os.system('mkdir {}'.format(usage_path))\n    if not os.path.exists(label_path):\n        os.system('mkdir {}'.format(label_path))\n    cv2.imwrite(img_path, img)\n\n    #     print('Write {}'.format(img_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Option A: Using cleaned.csv file to filter the training dataset\n\nSince I have run this multiple times, I have obtained the `cleaned.csv` file which you will also obtain from the *Cleaning up* section of this kernel.\n\nRun the code below (Option A) and don't run Option B if you have obtained cleaned.csv file."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Copy cleaned.csv file to working folder\npath = '/kaggle/input/cleaned/cleaned.csv'\ndestination = '/kaggle/working/fer-challenge/images/cleaned.csv'\nshutil.copyfile(path, destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change path to where we formed our images\npath = \"/kaggle/working/fer-challenge/images\"\ndf = pd.read_csv(path+'/cleaned.csv', header='infer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ndata = ImageDataBunch.from_csv(path, folder=\".\", valid_pct=0.2, csv_labels='cleaned.csv',\nds_tfms=get_transforms(), size=224, num_workers=8).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Option B: Load the training dataset from folder without using cleaned.csv file\n\nUncomment and run this code instead of *Option A* if this is your first time running the kernel and you haven't obtained a cleaned.csv file yet."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # change path to where we formed our images\n# path = \"/kaggle/working/fer-challenge/images\"\n# os.chdir(path)\n\n# # bs = 64\n# tfms = get_transforms(do_flip=False)\n# data = ImageDataBunch.from_folder(path, train = \"Training\", valid_pct=0.2, ds_tfms=tfms, size=26, num_workers=0, bs = 64)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(f\"Classes in our data: {data.classes}\\nNumber of classes: {data.c}\\nTraining Dataset Length: {len(data.train_ds)}\\nValidation Dataset Length: {len(data.valid_ds)}\")\n\ndata.show_batch(rows=3, columns = 5, figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model\n\nTo train a model properly, I followed [Poonam's](https://forums.fast.ai/t/why-do-we-need-to-unfreeze-the-learner-everytime-before-retarining-even-if-learn-fit-one-cycle-works-fine-without-learn-unfreeze/41614/5) advice on the fastai forum on when to freeze and unfreeze the learner during model training. I suggested reading her approach to understanding how to optimize your model better."},{"metadata":{"trusted":false},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet34, metrics=[accuracy,error_rate])\nlearn.fit_one_cycle(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('stage-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training with the backbone frozen allows us to only train the untrained layers in the head. Once those layers have converged somewhat, we unfreeze the entire model and continue training.\n\n> Note: With the fastai library, loading the model will load it in a frozen state by default."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('stage-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the learning rate finder, we are looking for the strongest downward slope that's kind of sticking around for quite a while. For this case, it seems that we don't have a downward slope so let's limit our learning rate between 3e<sup>-6</sup> and 3e<sup>-3</sup>."},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(3e-6,3e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.save('stage-2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interpretation\n\nWe can use the ClassificationInterpretation class to have a look at what's going on."},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.load('stage-2');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"interp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning Up\n\nSome of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be there.\n\nUsing the `ImageCleaner` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong."},{"metadata":{},"cell_type":"markdown","source":"First, we need to get the file paths from our top_losses. We can do this with `.from_toplosses`. We then feed the top losses indexes and corresponding dataset to `ImageCleaner`.\n\nNotice that the widget will not delete images directly from disk but it will create a new csv file `cleaned.csv` from where you can create a new ImageDataBunch with the corrected labels to continue training your model.\n\nNote: Please Set the Number of images to a number that you'd like to view:\nex: ```n_imgs=100```"},{"metadata":{"trusted":false},"cell_type":"code","source":"db = (ImageList.from_folder(\"/kaggle/working/fer-challenge/images/Training\")\n                   .split_none()\n                   .label_from_folder()\n                   .transform(get_transforms(), size=224)\n                   .databunch()\n     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)\n\nlearn_cln.load('/kaggle/working/fer-challenge/images/models/stage-2');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ds, idxs = DatasetFormatter().from_toplosses(learn_cln)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using `ImageCleaner` we will get the widget running inside our kernel and we can correct the labels or delete images that don't with any of our labels. This is important to reduce the noise in our dataset and increase the performance of our learner."},{"metadata":{"trusted":false},"cell_type":"code","source":"ImageCleaner(ds, idxs, path, batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Flag photos for deletion by clicking 'Delete'. Then click 'Next Batch' to delete flagged photos and keep the rest in that row. ImageCleaner will show you a new row of images until there is no more to show. In this case, the widget will show you images until there are none left from top_losses.ImageCleaner(ds, idxs)\n\nYou can also find duplicates in your dataset and delete them! To do this, you need to run .from_similars to get the potential duplicates' ids and then run ImageCleaner with duplicates=True. The API works similarly as with misclassified images: just choose the ones you want to delete and click 'Next Batch' until there are no more images left."},{"metadata":{},"cell_type":"markdown","source":"## Validating the test set\n\nSince we were given the test set with labels out of the box, we will have to approach this as if we are validating our model rather than testing an unlabeled set of images. To do that, we will simply create a `data_test` from the images we have split my folders `Training` and `PublicTest` then validate to see how well our model performed. We do this rather than submitting the results because submissions for this competition is closed. For more information check out the [fastai docs](https://docs.fast.ai/data_block.html#Add-a-test-set)."},{"metadata":{"trusted":false},"cell_type":"code","source":"learn.load('stage-2')\n# ds_tfms=get_transforms(), size=224, num_workers=8\ndata_test = (ImageList.from_folder(path)\n            .split_by_folder(train='Training', valid='PublicTest')\n            .label_from_folder()\n            .transform(tfms=get_transforms(), size=224)\n            .databunch()\n            .normalize()\n        )\n\nloss, acc, err_r = learn.validate(data_test.valid_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = str(np.round(loss, 3))\nprint(f\"Our final model's training loss: {loss}, with Accuracy: {round(acc.item(), 3)} and Error Rate: {round(err_r.item(), 3)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Putting the model in production\n\nTo put my model in production, I used lankinen's approach and followed his instructions in his [medium article](https://medium.com/@lankinen/fastai-model-to-production-this-is-how-you-make-web-app-that-use-your-model-57d8999450cf).\n\n### Notes\n>When trying to install `torch_nightly`, the URL provided gave me a 404 error, to get around it, I visited the URL and manually found the latest version applicable to my environment (Ubunutu 18) and installed it.\n>\n>`wget https://download.pytorch.org/whl/nightly/cpu/torch_nightly-1.2.0.dev20190805%2Bcpu-cp36-cp36m-linux_x86_64.whl\npip3 install torch_nightly-1.2.0.dev20190805%2Bcpu-cp36-cp36m-linux_x86_64.whl`\n>\n>I also had to use t2.large instance which provides 8gb of RAM and increased the volume to 25gb because I ran out of memory and disk  space while installing fastai library.\n>\n>We will need export.pkl file which we get from `data.export()`\n>\n>Finally, just before loading up the server, you should update torchvision's installing by type:\n>`pip3 install torchvision`"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":4}